{
 "cells": [
  {
   "cell_type": "code",
   "id": "b310e470",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T07:49:15.991647Z",
     "start_time": "2025-10-23T07:49:15.928300Z"
    }
   },
   "source": [
    "import os, sys, json, numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def _import_or_fail():\n",
    "    err_msgs = []\n",
    "    ocr_utils = None\n",
    "    for try_mod in (\"ocr_utils\", \"model\", \"utils\", \"dataset\"):\n",
    "        try:\n",
    "            ocr_utils = __import__(try_mod, fromlist=[\"*\"])\n",
    "            if all(hasattr(ocr_utils, name) for name in (\"set_seed\",\"load_split\",\"split_train_valid\")):\n",
    "                break\n",
    "        except Exception as e:\n",
    "            err_msgs.append(f\"[warn] import {try_mod} failed: {e}\")\n",
    "            ocr_utils = None\n",
    "    if ocr_utils is None:\n",
    "        raise ImportError(\"Could not import set_seed/load_split/split_train_valid from ocr_utils/model/utils/dataset.\\n\" + \"\\n\".join(err_msgs))\n",
    "\n",
    "    train_mod = __import__(\"train\", fromlist=[\"*\"])\n",
    "    assert all(hasattr(train_mod, nm) for nm in (\"train_one_model\",\"evaluate_and_save\",\"_ensure_X\",\"build_model\"))\n",
    "    return ocr_utils, train_mod\n",
    "\n",
    "ocr_utils, train_mod = _import_or_fail()\n",
    "set_seed = getattr(ocr_utils, \"set_seed\")\n",
    "load_split = getattr(ocr_utils, \"load_split\")\n",
    "split_train_valid = getattr(ocr_utils, \"split_train_valid\")\n",
    "\n",
    "train_one_model = getattr(train_mod, \"train_one_model\")\n",
    "evaluate_and_save = getattr(train_mod, \"evaluate_and_save\")\n",
    "_ensure_X = getattr(train_mod, \"_ensure_X\")\n",
    "build_model = getattr(train_mod, \"build_model\")\n",
    "\n",
    "print(\"[OK] Imports ready.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Imports ready.\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "18e99247",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T07:50:46.545626Z",
     "start_time": "2025-10-23T07:50:46.482104Z"
    }
   },
   "source": [
    "\n",
    "TRAIN_DIR = \"../data/train\"\n",
    "TEST_DIR  = \"../data/test\"\n",
    "MODEL     = \"cnn\"\n",
    "IMAGE_SZ  = 32\n",
    "EPOCHS    = 10\n",
    "LR        = 1e-3\n",
    "BATCH     = 128\n",
    "HIDDEN    = [128]\n",
    "USE_DROPOUT   = True\n",
    "DROPOUT_RATIO = 0.5\n",
    "SEED = 42\n",
    "OUT_ROOT = \"runs\"\n",
    "set_seed(SEED)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "6ff4a35e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T07:50:23.495801Z",
     "start_time": "2025-10-23T07:49:16.065771Z"
    }
   },
   "source": [
    "\n",
    "print(f\"[Load][Train] {TRAIN_DIR}\")\n",
    "Xtr_all, ytr_all, label2idx, idx2label, stats_tr = load_split(\n",
    "    TRAIN_DIR, image_size=IMAGE_SZ, filter_to_train_labels=None, char_filter_fn=None\n",
    ")\n",
    "print(\"Train stats:\", stats_tr)\n",
    "\n",
    "Xtr, ytr, Xva, yva = split_train_valid(Xtr_all, ytr_all, valid_ratio=0.2, seed=SEED)\n",
    "\n",
    "if MODEL == \"cnn\":\n",
    "    Xtr = Xtr.reshape(len(Xtr), IMAGE_SZ, IMAGE_SZ)\n",
    "    Xva = Xva.reshape(len(Xva), IMAGE_SZ, IMAGE_SZ)\n",
    "    input_info = (1, IMAGE_SZ, IMAGE_SZ)\n",
    "else:\n",
    "    input_info = IMAGE_SZ * IMAGE_SZ\n",
    "\n",
    "output_size = len(label2idx)\n",
    "print(\"[Info] classes:\", output_size, \"input_info:\", input_info)\n",
    "\n",
    "net, best = train_one_model(\n",
    "    Xtr, ytr, Xva, yva,\n",
    "    input_info=input_info, output_size=output_size,\n",
    "    model_type=MODEL,\n",
    "    hidden_sizes=HIDDEN,\n",
    "    lr=LR, batch_size=BATCH, epochs=EPOCHS,\n",
    "    use_batchnorm=(MODEL==\"mlp\"),\n",
    "    use_dropout=USE_DROPOUT, dropout_ratio=DROPOUT_RATIO,\n",
    "    optimizer_name=\"adam\", seed=SEED,\n",
    ")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Load][Train] ../data/train\n",
      "[../data/train] 100/814 used=203\n",
      "[../data/train] 200/814 used=402\n",
      "[../data/train] 300/814 used=598\n",
      "[../data/train] 400/814 used=790\n",
      "[../data/train] 500/814 used=985\n",
      "[../data/train] 600/814 used=1185\n",
      "[../data/train] 700/814 used=1384\n",
      "[../data/train] 800/814 used=1584\n",
      "Train stats: defaultdict(<class 'int'>, {'skipped_non_single': 32197, 'used': 1612})\n",
      "[Info] classes: 1103 input_info: (1, 32, 32)\n",
      "[CNN][Epoch 001] train_acc=0.0054  val_acc=0.0000\n",
      "[CNN][Epoch 002] train_acc=0.0047  val_acc=0.0000\n",
      "[CNN][Epoch 003] train_acc=0.0101  val_acc=0.0000\n",
      "[CNN][Epoch 004] train_acc=0.0124  val_acc=0.0000\n",
      "[CNN][Epoch 005] train_acc=0.0264  val_acc=0.0000\n",
      "[CNN][Epoch 006] train_acc=0.0271  val_acc=0.0000\n",
      "[CNN][Epoch 007] train_acc=0.0419  val_acc=0.0000\n",
      "[CNN][Epoch 008] train_acc=0.0597  val_acc=0.0000\n",
      "[CNN][Epoch 009] train_acc=0.0814  val_acc=0.0000\n",
      "[CNN][Epoch 010] train_acc=0.1264  val_acc=0.0031\n",
      "=> Restored best epoch 10 (val_acc=0.0031)\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "b27e0126",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T07:51:43.731350Z",
     "start_time": "2025-10-23T07:50:49.049155Z"
    }
   },
   "source": [
    "\n",
    "print(f\"[Load][Test] {TEST_DIR}\")\n",
    "Xte, yte, _, _, stats_te = load_split(\n",
    "    TEST_DIR, image_size=IMAGE_SZ, filter_to_train_labels=label2idx, char_filter_fn=None\n",
    ")\n",
    "print(\"Test stats:\", stats_te)\n",
    "\n",
    "if MODEL == \"cnn\":\n",
    "    Xte = Xte.reshape(len(Xte), IMAGE_SZ, IMAGE_SZ)\n",
    "\n",
    "ts = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "out_dir = os.path.join(OUT_ROOT, f\"{MODEL}_{ts}\")\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "with open(os.path.join(out_dir, \"label2idx.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({k:int(v) for k,v in label2idx.items()}, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "acc, cm = evaluate_and_save(net, Xte, yte, idx2label, out_dir=out_dir)\n",
    "np.save(os.path.join(out_dir, \"cm.npy\"), cm)\n",
    "\n",
    "state = net.snapshot_state()\n",
    "np.savez(os.path.join(out_dir, \"model_state.npz\"), **state)\n",
    "\n",
    "print(\"[Done] out_dir =\", out_dir, \"  test_acc =\", acc)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Load][Test] ../data/test\n",
      "[../data/test] 100/1057 used=115\n",
      "[../data/test] 200/1057 used=236\n",
      "[../data/test] 300/1057 used=361\n",
      "[../data/test] 400/1057 used=494\n",
      "[../data/test] 500/1057 used=610\n",
      "[../data/test] 600/1057 used=733\n",
      "[../data/test] 700/1057 used=870\n",
      "[../data/test] 800/1057 used=991\n",
      "[../data/test] 900/1057 used=1109\n",
      "[../data/test] 1000/1057 used=1232\n",
      "Test stats: defaultdict(<class 'int'>, {'skipped_non_single': 41721, 'skipped_unknown_label': 812, 'used': 1288})\n",
      "[Validation] accuracy = 0.0070  (N=1288)\n",
      "Saved: runs\\cnn_20251023-165141\\cm.npy and labels.json\n",
      "[Done] out_dir = runs\\cnn_20251023-165141   test_acc = 0.006987577639751553\n"
     ]
    }
   ],
   "execution_count": 26
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
